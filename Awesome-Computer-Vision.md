# Awesome Computer Vision [![Awesome CV](https://img.shields.io/badge/Awesome-Computer%20Vision-blue?style=for-the-badge)](https://github.com/<YOUR_REPO>)

A modern, curated list of awesome computer vision resources -- projects,
libraries, papers, datasets, and applications.\
This repo is inspired by older inactive lists but updated for 2023--present
with fresh categories and resources.

------------------------------------------------------------------------

## Main Topics

-   **Image Classification**
    -   [YOLOv8](https://github.com/ultralytics/notebooks/tree/main) --
        State-of-the-art real-time detection & classification.
    -   [EfficientNet](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet)
        -- Highly efficient image classification.
-   **Object Detection**
    -   [Detectron2](https://github.com/facebookresearch/detectron2) --
        Facebook AI's modular detection library.
    -   [MMDetection](https://github.com/open-mmlab/mmdetection) --
        Powerful detection toolbox from OpenMMLab.

-   **Segmentation**
    -   [Segment
        Anything](https://github.com/facebookresearch/segment-anything)
        -- Foundation model for segmentation.
    -   [Mask R-CNN](https://github.com/matterport/Mask_RCNN) -- Classic
        deep learning segmentation framework.
    -   [segment-anything](https://github.com/facebookresearch/segment-anything)
        Segment Anything in Images and Videos.
-   **Tracking**
    -   [ByteTrack](https://github.com/ifzhang/ByteTrack) --
        High-performance multi-object tracking.
    -   [DeepSORT](https://github.com/nwojke/deep_sort) -- Tracking with
        appearance embeddings.

## The Starter Computer Vision Projects 

1. [Ultralytics / ultralytics (YOLOv8 & tools)](https://github.com/ultralytics/ultralytics) — fast end-to-end object detection/segmentation/classification.  
2. [facebookresearch / detectron2](https://github.com/facebookresearch/detectron2) — modular detection & segmentation library (Mask R-CNN, RetinaNet, etc.).  
3. [open-mmlab / mmdetection](https://github.com/open-mmlab/mmdetection) — OpenMMLab detection toolbox & benchmarks.  
4. [facebookresearch / segment-anything (SAM)](https://github.com/facebookresearch/segment-anything) — foundation model for promptable segmentation.  
5. [pytorch / vision (torchvision)](https://github.com/pytorch/vision) — datasets, models, and transforms for PyTorch CV.  
6. [rwightman / timm (PyTorch Image Models)](https://github.com/rwightman/pytorch-image-models) — large collection of backbones and pretrained weights.  
7. [open-mmlab / mmsegmentation](https://github.com/open-mmlab/mmsegmentation) — semantic segmentation toolbox.  
8. [open-mmlab / mmclassification](https://github.com/open-mmlab/mmclassification) — image classification toolbox.  
9. [open-mmlab / mmcv](https://github.com/open-mmlab/mmcv) — foundational library for OpenMMLab projects.  
10. [open-mmlab / mmdetection3d](https://github.com/open-mmlab/mmdetection3d) — 3D detection toolbox (LiDAR / multi-modal).  
11. [ultralytics / yolov5 (community forks & legacy)](https://github.com/ultralytics/yolov5) — popular YOLOv5 repo and ecosystem.  
12. [facebookresearch / DINO (self-supervised)](https://github.com/facebookresearch/dino) — self-supervised ViT/CNN representation learning (paper + code).  
13. [openai / CLIP (official & community)](https://github.com/openai/CLIP) — image-text representations and zero-shot models.  
14. [CompVis / stable-diffusion (generative, image)](https://github.com/CompVis/stable-diffusion) — image diffusion models with many CV uses.  
15. [NVlabs / stylegan3](https://github.com/NVlabs/stylegan3) — high-quality image generation (useful for synthetic CV datasets).  
16. [google-research / vision_transformer (ViT)](https://github.com/google-research/vision_transformer) — original ViT code & examples.  
17. [microsoft / Swin-Transformer](https://github.com/microsoft/Swin-Transformer) — hierarchical vision transformer backbone.  
18. [open-mmlab / mmtracking](https://github.com/open-mmlab/mmtracking) — multi-object tracking toolbox.  
19. [ifzhang / ByteTrack](https://github.com/ifzhang/ByteTrack) — high-performance multi-object tracker.  
20. [nwojke / deep_sort](https://github.com/nwojke/deep_sort) — classic tracker with appearance embeddings.  
21. [open-mmlab / mmpose](https://github.com/open-mmlab/mmpose) — human/body pose estimation toolbox.  
22. [charlesq34 / pointnet2 (PointNet++)](https://github.com/charlesq34/pointnet2) — point-cloud learning (3D).  
23. [open3d / open3d](https://github.com/isl-org/Open3D) — 3D data processing, visualization, and neural modules.  
24. [facebookresearch / detectron (legacy)](https://github.com/facebookresearch/Detectron) — Detectron v1 research code (historical).  
25. [ultralytics / yolov8-notebooks & examples](https://github.com/ultralytics/notebooks) — ready-to-run YOLOv8 notebooks & demos.  
26. [facebookresearch / SAM-2 (sam2)](https://github.com/facebookresearch/sam2) — SAM-video / SAM2 developments (promptable segmentation evolution).  
27. [open-mmlab / mmdetection3d (again — LiDAR & multi-sensor)](https://github.com/open-mmlab/mmdetection3d) — 3D detection (included here for emphasis on multi-modal CV).  
28. [ultralytics / yolov8 (alt repo for tooling)](https://github.com/DeGirum/ultralytics_yolov8) — alternate implementations & tooling for YOLOv8.  
29. [fiftyone / fiftyone](https://github.com/voxel51/fiftyone) — dataset inspection, visualization, and model evaluation platform.  
30. [openvinotoolkit / cvat](https://github.com/openvinotoolkit/cvat) — Computer Vision Annotation Tool (video/image labeling).  
31. [albumentations-team / albumentations](https://github.com/albumentations-team/albumentations) — fast image augmentation library used in many CV pipelines.  
32. [ultralytics / open-source deployment examples (YOLO export & deployment)](https://github.com/ultralytics) — export & deployment ecosystem for CV models.  
33. [roboflow / roboflow-ai] (https://github.com/roboflow) — dataset tooling, augmentation, and deployment examples (community repos).  
34. [open-mmlab / mmgeneration](https://github.com/open-mmlab/mmgeneration) — generative model toolbox (GANs, diffusion).  
35. [facebookresearch / slowfast (video understanding)](https://github.com/facebookresearch/SlowFast) — video action recognition models & code.  
36. [open-mmlab / mmaction2 (video)](https://github.com/open-mmlab/mmaction2) — video understanding toolbox.  
37. [cornellius-gp / catalyst (training & research framework)](https://github.com/catalyst-team/catalyst) — research training loops and reproducibility helpers (useful in CV).  
38. [kornia / kornia](https://github.com/kornia/kornia) — differentiable computer vision operators for PyTorch (augmentation, geometric transforms).  
39. [ultralytics / roboflow-models integration examples (community)](https://github.com/roboflow/roboflow-pytorch) — practical CV training examples & connectors.  
40. [google-research / nerf (NeRF repos & variants)](https://github.com/google-research/google-research/tree/master/nerf) — neural radiance fields code (3D & view synthesis).


------------------------------------------------------------------------

## Learning Paradigms -- projects

1. [google-research / simclr](https://github.com/google-research/simclr) — Simple framework for contrastive self-supervised learning.  
2. [facebookresearch / moco](https://github.com/facebookresearch/moco) — Momentum Contrast for self-supervised representations.  
3. [facebookresearch / moco-v3](https://github.com/facebookresearch/moco-v3) — MoCo-v3 with Vision Transformers.  
4. [facebookresearch / swav](https://github.com/facebookresearch/swav) — Online clustering for SSL.  
5. [facebookresearch / byol](https://github.com/deepmind/deepmind-research/tree/master/byol) — Bootstrap Your Own Latent (BYOL).  
6. [facebookresearch / vicreg](https://github.com/facebookresearch/vicreg) — Variance-Invariance-Covariance Regularization for SSL.  
7. [facebookresearch / barlowtwins](https://github.com/facebookresearch/barlowtwins) — Self-supervised learning with redundancy reduction.  
8. [facebookresearch / DINO](https://github.com/facebookresearch/dino) — Self-distillation with no labels (Vision Transformers).  
9. [microsoft / unilm](https://github.com/microsoft/unilm) — Universal pretraining for language and vision.  
10. [google-research / big_transfer (BiT)](https://github.com/google-research/big_transfer) — Transfer learning with large-scale models.  
11. [huggingface / transformers](https://github.com/huggingface/transformers) — Hugely popular pretrained model hub (CV + NLP).  
12. [timm / pytorch-image-models](https://github.com/rwightman/pytorch-image-models) — Large set of pretrained CV models for transfer learning.  
13. [facebookresearch / domainbed](https://github.com/facebookresearch/DomainBed) — Benchmark for domain generalization & transfer.  
14. [pytorch / lightning-bolts](https://github.com/Lightning-AI/lightning-bolts) — Pretrained models and SSL implementations.  
15. [open-mmlab / mmselfsup](https://github.com/open-mmlab/mmselfsup) — Self-supervised learning toolbox.  
16. [open-mmlab / mmfewshot](https://github.com/open-mmlab/mmfewshot) — Few-shot learning library.  
17. [huggingface / diffusers](https://github.com/huggingface/diffusers) — Diffusion models for generative and transfer tasks.  
18. [lucidrains / vit-pytorch](https://github.com/lucidrains/vit-pytorch) — Vision Transformer implementations for transfer learning.  
19. [lucidrains / perceiver-pytorch](https://github.com/lucidrains/perceiver-pytorch) — Perceiver models (multi-modal transfer).  
20. [microsoft / DeepSpeed](https://github.com/microsoft/DeepSpeed) — Efficient training framework for scaling SSL/transfer.  
21. [microsoft / LoRA](https://github.com/microsoft/LoRA) — Low-Rank Adaptation of large models (transfer).  
22. [huggingface / peft](https://github.com/huggingface/peft) — Parameter-efficient fine-tuning.  
23. [lucidrains / DALLE-pytorch](https://github.com/lucidrains/DALLE-pytorch) — Generative transfer learning approaches.  
24. [huggingface / accelerate](https://github.com/huggingface/accelerate) — Training large models (transfer/self-supervised).  
25. [facebookresearch / habitat-lab](https://github.com/facebookresearch/habitat-lab) — Embodied AI simulation, RL for CV tasks.  
26. [allenai / allenact](https://github.com/allenai/allenact) — Modular RL framework for vision-driven embodied agents.  
27. [openai / spinningup](https://github.com/openai/spinningup) — Educational RL repo, including visual RL.  
28. [DLR-RM / rl-baselines3-zoo](https://github.com/DLR-RM/rl-baselines3-zoo) — RL baseline training with SB3.  
29. [openai / gym](https://github.com/openai/gym) — Classic RL environments (visual-based RL tasks included).  
30. [facebookresearch / habitat-sim](https://github.com/facebookresearch/habitat-sim) — 3D environments for vision + RL.  
31. [unity-technologies / ml-agents](https://github.com/Unity-Technologies/ml-agents) — RL agents in 3D simulated environments.  
32. [deepmind / acme](https://github.com/deepmind/acme) — RL framework from DeepMind (multi-modal).  
33. [deepmind / dm-control](https://github.com/deepmind/dm_control) — RL environment suite with CV inputs.  
34. [openai / baselines](https://github.com/openai/baselines) — Classic RL baselines.  
35. [pytorch / ignite](https://github.com/pytorch/ignite) — Training paradigms with SSL/RL extensions.  
36. [google-research / RLDS](https://github.com/google-research/rlds) — Reinforcement Learning Datasets.  
37. [facebookresearch / habitat-baselines](https://github.com/facebookresearch/habitat-baselines) — RL baselines for Habitat.  
38. [facebookresearch / torchbeast](https://github.com/facebookresearch/torchbeast) — Distributed RL agent training.  
39. [deepmind / trfl](https://github.com/deepmind/trfl) — TensorFlow RL components.  
40. [stable-baselines3 / stable-baselines3](https://github.com/DLR-RM/stable-baselines3) — Popular RL library with CV-compatible algorithms.

------------------------------------------------------------------------

## Generative Models

-   [StyleGAN3](https://github.com/NVlabs/stylegan3) -- High-quality
    image synthesis.
-   [Stable Diffusion](https://github.com/CompVis/stable-diffusion) --
    Open-source diffusion model for images.
-   [Talking Head
    Generation](https://github.com/yuval-alaluf/face-vid2vid) --
    Realistic talking face models.

## Generative Models —- projects

1. [CompVis / stable-diffusion](https://github.com/CompVis/stable-diffusion) — Breakthrough diffusion model for image generation.  
2. [Automatic1111 / stable-diffusion-webui](https://github.com/AUTOMATIC1111/stable-diffusion-webui) — Popular SD web UI with extensions.  
3. [Stability-AI / stablediffusion](https://github.com/Stability-AI/stablediffusion) — Official Stability AI repo for diffusion models.  
4. [huggingface / diffusers](https://github.com/huggingface/diffusers) — Hugging Face toolkit for diffusion models.  
5. [runwayml / stable-diffusion](https://github.com/runwayml/stable-diffusion) — RunwayML’s fork with optimizations.  
6. [CompVis / latent-diffusion](https://github.com/CompVis/latent-diffusion) — Predecessor to Stable Diffusion.  
7. [lucidrains / DALLE-pytorch](https://github.com/lucidrains/DALLE-pytorch) — Implementation of DALL·E in PyTorch.  
8. [openai / guided-diffusion](https://github.com/openai/guided-diffusion) — OpenAI’s official diffusion models repo.  
9. [openai / glide-text2im](https://github.com/openai/glide-text2im) — GLIDE text-to-image diffusion model.  
10. [openai / jukebox](https://github.com/openai/jukebox) — Generative model for music and audio.  
11. [NVlabs / stylegan3](https://github.com/NVlabs/stylegan3) — High-fidelity GAN for image synthesis.  
12. [NVlabs / stylegan2-ada-pytorch](https://github.com/NVlabs/stylegan2-ada-pytorch) — StyleGAN2 with adaptive augmentation.  
13. [NVlabs / stylegan](https://github.com/NVlabs/stylegan) — Original StyleGAN implementation.  
14. [rosinality / stylegan2-pytorch](https://github.com/rosinality/stylegan2-pytorch) — PyTorch StyleGAN2 repo.  
15. [ShahRukhKhan / stylegan2-distillation](https://github.com/ShahRukhKhan/stylegan2-distillation) — Distilling StyleGANs for fast inference.  
16. [facebookresearch / animated-drawings](https://github.com/facebookresearch/AnimatedDrawings) — Turn drawings into animations.  
17. [openai / CLIP](https://github.com/openai/CLIP) — Connects images and text, used for generative prompting.  
18. [openai / point-e](https://github.com/openai/point-e) — Text-to-3D point cloud generation.  
19. [CompVis / taming-transformers](https://github.com/CompVis/taming-transformers) — VQGAN implementation.  
20. [openai / DALL-E](https://github.com/openai/DALL-E) — Original DALL·E demo repo.  
21. [openai / dalle-2-preview](https://github.com/openai/dalle-2-preview) — Research preview of DALL·E 2.  
22. [kandinsky-community / kandinsky-2](https://github.com/ai-forever/Kandinsky-2) — Diffusion model alternative to SD.  
23. [huggingface / transformers](https://github.com/huggingface/transformers) — Includes generative multimodal models.  
24. [lucidrains / imagen-pytorch](https://github.com/lucidrains/imagen-pytorch) — Imagen implementation in PyTorch.  
25. [lucidrains / maskgit-pytorch](https://github.com/lucidrains/maskgit-pytorch) — Masked generative transformers.  
26. [lucidrains / dalle2-pytorch](https://github.com/lucidrains/dalle2-pytorch) — PyTorch implementation of DALL·E 2.  
27. [lucidrains / vq-vae-2-pytorch](https://github.com/lucidrains/vq-vae-2-pytorch) — VQ-VAE-2 implementation.  
28. [lucidrains / parti-pytorch](https://github.com/lucidrains/parti-pytorch) — Parti text-to-image model.  
29. [openai / whisper](https://github.com/openai/whisper) — Generative ASR model (audio-to-text).  
30. [TencentARC / GFPGAN](https://github.com/TencentARC/GFPGAN) — Face restoration generative model.  
31. [TencentARC / Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) — Super-resolution generative model.  
32. [TencentARC / AnimeGAN](https://github.com/TachibanaYoshino/AnimeGANv2) — GAN for anime-style transfer.  
33. [CompVis / VQGAN-CLIP](https://github.com/CompVis/vqgan-clip) — Combining VQGAN with CLIP for image generation.  
34. [huggingface / diffusers-examples](https://github.com/huggingface/diffusers/tree/main/examples) — Generative diffusion examples.  
35. [google / parti](https://github.com/google-research/parti) — Google’s Parti generative model.  
36. [deepmind / biggan-deep](https://github.com/deepmind/biggan-deep) — BigGAN generative models.  
37. [openai / muse](https://github.com/openai/muse) — Multimodal generative experiments.  
38. [deepmind / dreamer](https://github.com/danijar/dreamer) — Generative RL model for world models.  
39. [deepmind / perceptual-metrics](https://github.com/deepmind/perceptual-metrics) — Generative perceptual similarity metrics.  
40. [mlfoundations / open_clip](https://github.com/mlfoundations/open_clip) — Open CLIP implementation for generative tasks.


------------------------------------------------------------------------

## 3D & Video Understanding

-   [NeRF (Nerfies)](https://github.com/google/nerfies) -- Neural
    Radiance Fields for 3D scenes.
-   [OpenMMLab Video](https://github.com/open-mmlab/mmaction2) -- Video
    understanding toolbox.
-   [PointNet++](https://github.com/charlesq34/pointnet2) -- Deep
    learning for 3D point clouds.

## 3D & Video Understanding -- projects

1. [google / nerfies](https://github.com/google/nerfies) — Dynamic Neural Radiance Fields for 3D reconstruction.  
2. [bmild / nerf](https://github.com/bmild/nerf) — Original NeRF implementation for novel view synthesis.  
3. [yenchenlin / NeRF-pytorch](https://github.com/yenchenlin/nerf-pytorch) — PyTorch NeRF implementation.  
4. [NVlabs / instant-ngp](https://github.com/NVlabs/instant-ngp) — Instant NeRF with GPU acceleration.  
5. [ashawkey / instant-ngp-onnx](https://github.com/ashawkey/instant-ngp-onnx) — NeRF with ONNX runtime.  
6. [open-mmlab / mmediting](https://github.com/open-mmlab/mmediting) — Video editing and frame interpolation.  
7. [open-mmlab / mmaction2](https://github.com/open-mmlab/mmaction2) — Video understanding toolbox (action recognition).  
8. [facebookresearch / SlowFast](https://github.com/facebookresearch/SlowFast) — Video recognition models from FAIR.  
9. [facebookresearch / PySlowFast](https://github.com/facebookresearch/SlowFast) — SlowFast PyTorch implementation.  
10. [kenshohara / 3D-ResNets-PyTorch](https://github.com/kenshohara/3D-ResNets-PyTorch) — 3D CNNs for action recognition.  
11. [open-mmlab / mmpose](https://github.com/open-mmlab/mmpose) — Human pose estimation toolbox.  
12. [open-mmlab / mmhuman3d](https://github.com/open-mmlab/mmhuman3d) — 3D human parametric model toolbox.  
13. [google / mediapipe](https://github.com/google/mediapipe) — Cross-platform vision pipelines (pose, hands, face).  
14. [isl-org / Open3D](https://github.com/isl-org/Open3D) — 3D data processing library.  
15. [isl-org / Open3D-ML](https://github.com/isl-org/Open3D-ML) — 3D deep learning with Open3D.  
16. [charlesq34 / pointnet](https://github.com/charlesq34/pointnet) — Deep learning on 3D point clouds.  
17. [charlesq34 / pointnet2](https://github.com/charlesq34/pointnet2) — PointNet++ implementation.  
18. [nicolas-chaulet / torch-points3d](https://github.com/nicolas-chaulet/torch-points3d) — Modular 3D deep learning library.  
19. [microsoft / voxelpose-pytorch](https://github.com/microsoft/voxelpose-pytorch) — Multi-view 3D pose estimation.  
20. [microsoft / MeshTransformer](https://github.com/microsoft/MeshTransformer) — Transformer for 3D meshes.  
21. [autonomousvision / occupancy_networks](https://github.com/autonomousvision/occupancy_networks) — 3D reconstruction from images.  
22. [autonomousvision / implicit-pdf](https://github.com/autonomousvision/implicit-pdf) — Implicit representations for 3D.  
23. [autonomousvision / dvr](https://github.com/autonomousvision/dvr) — Differentiable volumetric rendering.  
24. [autonomousvision / pixelnerf](https://github.com/autonomousvision/pixelnerf) — PixelNeRF model.  
25. [facebookresearch / pytorch3d](https://github.com/facebookresearch/pytorch3d) — Deep learning for 3D data.  
26. [NVIDIAGameWorks / kaolin](https://github.com/NVIDIAGameWorks/kaolin) — NVIDIA’s 3D deep learning library.  
27. [openai / shapes3d](https://github.com/deepmind/shapes3d) — 3D synthetic dataset for representation learning.  
28. [google-research / animatable-nerf](https://github.com/google/animatable-nerf) — NeRFs for animatable humans.  
29. [facebookresearch / NeRV](https://github.com/facebookresearch/NeRV) — Neural representations for video.  
30. [google-research / deepmind3d](https://github.com/google-research/deepmind3d) — Implicit 3D representations.  
31. [vt-vl-lab / vid2vid](https://github.com/NVIDIA/vid2vid) — Video-to-video synthesis.  
32. [google / maniskill](https://github.com/haosulab/ManiSkill) — 3D RL environment with manipulation.  
33. [microsoft / Deep3DFaceReconstruction](https://github.com/microsoft/Deep3DFaceReconstruction) — 3D face reconstruction.  
34. [yfeng95 / Deep3DFaceRecon_pytorch](https://github.com/yfeng95/Deep3DFaceRecon_pytorch) — PyTorch 3D face recon.  
35. [THUDM / CogVideo](https://github.com/THUDM/CogVideo) — Large-scale video generation.  
36. [openai / video-pretraining](https://github.com/openai/video-pretraining) — Learning video representations.  
37. [deepmind / perceiver](https://github.com/deepmind/deepmind-research/tree/master/perceiver) — Perceiver for multi-modal, video & 3D.  
38. [facebookresearch / CoTracker](https://github.com/facebookresearch/co-tracker) — Long-term tracking in videos.  
39. [facebookresearch / detectron2-video](https://github.com/facebookresearch/detectron2/tree/main/projects/Video) — Video extensions of Detectron2.  
40. [open-mmlab / mmdet3d](https://github.com/open-mmlab/mmdetection3d) — 3D object detection toolbox.  


------------------------------------------------------------------------

## Modern Architectures

-   [Vision Transformer
    (ViT)](https://github.com/google-research/vision_transformer)
-   [Swin Transformer](https://github.com/microsoft/Swin-Transformer)
-   [Graph Neural
    Networks](https://github.com/nnzhan/Awesome-Graph-Neural-Networks)

## Modern Architectures —-projects

1. [google-research / vision_transformer](https://github.com/google-research/vision_transformer) — Official Vision Transformer (ViT) repo.  
2. [lucidrains / vit-pytorch](https://github.com/lucidrains/vit-pytorch) — PyTorch implementation of ViT.  
3. [facebookresearch / DeiT](https://github.com/facebookresearch/deit) — Data-efficient Vision Transformers.  
4. [microsoft / Swin-Transformer](https://github.com/microsoft/Swin-Transformer) — Hierarchical vision transformer.  
5. [microsoft / CvT](https://github.com/microsoft/CvT) — Convolutional vision transformers.  
6. [facebookresearch / convnext](https://github.com/facebookresearch/ConvNeXt) — Modernized CNN architecture.  
7. [rwightman / efficientnet-jax](https://github.com/google/automl/tree/master/efficientnetv2) — EfficientNetV2 models.  
8. [rwightman / pytorch-image-models (timm)](https://github.com/rwightman/pytorch-image-models) — Huge collection of modern architectures.  
9. [facebookresearch / regnet](https://github.com/facebookresearch/pycls) — RegNet scalable network design.  
10. [facebookresearch / pycls](https://github.com/facebookresearch/pycls) — Image classification codebase (RegNet, ResNeXt).  
11. [facebookresearch / ClassyVision](https://github.com/facebookresearch/ClassyVision) — Research platform for large-scale training.  
12. [google-research / BigTransfer (BiT)](https://github.com/google-research/big_transfer) — Pretrained large-scale models.  
13. [google / automl](https://github.com/google/automl) — EfficientNet and NAS models.  
14. [facebookresearch / Hydra](https://github.com/facebookresearch/hydra) — Config-driven training for modern models.  
15. [facebookresearch / ConvNeXt-V2](https://github.com/facebookresearch/ConvNeXt-V2) — ConvNeXt upgrades with better performance.  
16. [facebookresearch / resnext](https://github.com/facebookresearch/ResNeXt) — ResNeXt architecture.  
17. [keras-team / keras-applications](https://github.com/keras-team/keras-applications) — Popular CNN backbones.  
18. [tensorflow / models](https://github.com/tensorflow/models) — TF official models (ResNet, EfficientNet, ViT).  
19. [google-research / vit-gan](https://github.com/google-research/vit-gan) — GANs with vision transformers.  
20. [microsoft / BEiT](https://github.com/microsoft/unilm/tree/master/beit) — BERT pretraining for vision.  
21. [microsoft / UViM](https://github.com/microsoft/unilm/tree/master/uvim) — Unified Vision Models.  
22. [facebookresearch / CaiT](https://github.com/facebookresearch/deit) — Class-attention in vision transformers.  
23. [facebookresearch / PiT](https://github.com/naver-ai/pit) — Pooling-based vision transformers.  
24. [facebookresearch / LV-ViT](https://github.com/zihangJiang/TokenLabeling) — Label-efficient ViTs.  
25. [microsoft / EVA](https://github.com/baaivision/EVA) — Transformer-based foundation vision model.  
26. [huggingface / transformers](https://github.com/huggingface/transformers) — Supports modern CV architectures (ViT, Swin).  
27. [facebookresearch / DINO](https://github.com/facebookresearch/dino) — Self-supervised ViTs.  
28. [facebookresearch / MaskFormer](https://github.com/facebookresearch/MaskFormer) — Transformer-based segmentation.  
29. [facebookresearch / Mask2Former](https://github.com/facebookresearch/Mask2Former) — General transformer for segmentation.  
30. [microsoft / CoAtNet](https://github.com/chinhsuanwu/coatnet-pytorch) — CoAtNet hybrid CNN-transformer.  
31. [apple / ml-mobilevit](https://github.com/apple/ml-mobilevit) — Lightweight MobileViT models.  
32. [apple / ml-cvnets](https://github.com/apple/ml-cvnets) — Efficient CV networks.  
33. [TencentARC / hrnet](https://github.com/HRNet/HRNet-Image-Classification) — High-resolution network.  
34. [TencentARC / mmsegmentation](https://github.com/open-mmlab/mmsegmentation) — Segmentation with modern backbones.  
35. [DeepVoltaire / VisionOutlooker](https://github.com/DeepVoltaire/VOLO) — Vision Outlooker (VOLO) transformer.  
36. [lucidrains / gmlp-pytorch](https://github.com/lucidrains/g-mlp-pytorch) — Gated MLP models.  
37. [facebookresearch / ConvMixer](https://github.com/facebookresearch/ConvNeXt/blob/main/README.md#convmixer) — Mixing convolutions for image classification.  
38. [google-research / gmlp](https://github.com/google-research/google-research/tree/master/gmlp) — Google’s Gated MLP for vision.  
39. [facebookresearch / twonets](https://github.com/facebookresearch/twonets) — Dual network architectures.  
40. [pytorch / torchvision](https://github.com/pytorch/vision) — Hub of modern and classic CV architectures.  


------------------------------------------------------------------------

## Specialized Applications

-   **Medical Imaging**
    -   [MONAI](https://github.com/Project-MONAI/MONAI) -- Deep learning
        for healthcare imaging.
-   **Autonomous Driving**
    -   [Apollo](https://github.com/ApolloAuto/apollo) -- Open
        autonomous driving platform.
-   **Remote Sensing**
    -   [TorchGeo](https://github.com/microsoft/torchgeo) -- Geospatial
        deep learning library.

## Specialized Applications — 40 curated resources

1. [facebookresearch / detectron2](https://github.com/facebookresearch/detectron2) — Object detection and segmentation.  
2. [ultralytics / yolov5](https://github.com/ultralytics/yolov5) — Real-time object detection.  
3. [ultralytics / yolov8](https://github.com/ultralytics/ultralytics) — Latest YOLO detection and segmentation framework.  
4. [microsoft / FasterRCNN](https://github.com/pytorch/vision/tree/main/references/detection) — Reference Faster R-CNN in PyTorch.  
5. [matterport / Mask_RCNN](https://github.com/matterport/Mask_RCNN) — Popular Mask R-CNN implementation.  
6. [facebookresearch / detectron](https://github.com/facebookresearch/Detectron) — Predecessor to detectron2.  
7. [TensorFlow / models / object_detection](https://github.com/tensorflow/models/tree/master/research/object_detection) — TF object detection API.  
8. [google-research / open-images-dataset](https://github.com/openimages/dataset) — Huge object detection dataset.  
9. [facebookresearch / SlowFast](https://github.com/facebookresearch/SlowFast) — Video recognition framework.  
10. [open-mmlab / mmaction2](https://github.com/open-mmlab/mmaction2) — Action recognition toolbox.  
11. [activitynet / ActivityNet](https://github.com/activitynet/ActivityNet) — Large-scale video benchmark.  
12. [CMU-Perceptual-Computing-Lab / openpose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) — Real-time human pose estimation.  
13. [facebookresearch / detectron2-pose](https://github.com/facebookresearch/detectron2/tree/main/projects/KeypointRCNN) — Pose estimation with detectron2.  
14. [microsoft / DeepHighResolutionNet.HumanPose](https://github.com/leoxiaobin/deep-high-resolution-net.pytorch) — HRNet for pose estimation.  
15. [microsoft / KinectBodyTracking](https://github.com/microsoft/Azure-Kinect-Body-Tracking-SDK) — Skeleton tracking with Azure Kinect.  
16. [google-research / mediapipe](https://github.com/google/mediapipe) — ML pipelines for face, hands, pose, etc.  
17. [davisking / dlib](https://github.com/davisking/dlib) — Face recognition and tracking.  
18. [serengil / deepface](https://github.com/serengil/deepface) — Simple face recognition for Python.  
19. [ageitgey / face_recognition](https://github.com/ageitgey/face_recognition) — Easy face recognition in Python.  
20. [opencv / opencv_contrib](https://github.com/opencv/opencv_contrib) — Extra modules (face, xfeatures2d, etc).  
21. [open-mmlab / mmtracking](https://github.com/open-mmlab/mmtracking) — Video object tracking.  
22. [visionml / Norfair](https://github.com/tryolabs/norfair) — Lightweight real-time 2D object tracking.  
23. [abewley / sort](https://github.com/abewley/sort) — Simple Online and Realtime Tracking.  
24. [nwojke / deep_sort](https://github.com/nwojke/deep_sort) — Deep SORT multi-object tracker.  
25. [facebookresearch / XMem](https://github.com/hkchengrex/XMem) — Video object segmentation.  
26. [tensorlayer / ST-GCN](https://github.com/yysijie/st-gcn) — Skeleton-based action recognition.  
27. [open-mmlab / mmhuman3d](https://github.com/open-mmlab/mmhuman3d) — 3D human parametric model toolkit.  
28. [facebookresearch / iBOT](https://github.com/facebookresearch/ibot) — Self-supervised ViT for detection/segmentation.  
29. [kornia / kornia](https://github.com/kornia/kornia) — Differentiable computer vision for PyTorch.  
30. [isl-org / Open3D](https://github.com/isl-org/Open3D) — 3D vision library.  
31. [PRBonn / evo](https://github.com/MichaelGrupp/evo) — Evaluation of odometry and SLAM.  
32. [ethz-asl / maplab](https://github.com/ethz-asl/maplab) — Visual-inertial mapping framework.  
33. [ethz-asl / ROVIOLI](https://github.com/ethz-asl/rovio) — Visual-inertial odometry.  
34. [raulmur / ORB_SLAM2](https://github.com/raulmur/ORB_SLAM2) — Landmark visual SLAM system.  
35. [UZ-SLAMLab / ORB_SLAM3](https://github.com/UZ-SLAMLab/ORB_SLAM3) — SLAM with stereo and inertial fusion.  
36. [intel-isl / OpenVINO](https://github.com/openvinotoolkit/openvino) — Optimized deployment for detection/pose.  
37. [google / mediapipe_face_mesh](https://github.com/google/mediapipe) — Detailed 3D face mesh.  
38. [shubham1810 / video-anomaly-detection](https://github.com/shubham1810/video-anomaly-detection) — Anomaly detection in surveillance video.  
39. [microsoft / SeeingAI](https://github.com/microsoft/SeeingAI) — Computer vision for accessibility.  
40. [openvinotoolkit / anomaly-detection](https://github.com/openvinotoolkit/anomaly-detection) — Industrial defect/anomaly detection.  


------------------------------------------------------------------------

## Resources

-   [Papers With Code](https://paperswithcode.com/) -- Benchmarked ML
    papers.
-   [CVPR Open Access](https://openaccess.thecvf.com/CVPR2025) -- CVPR
    conference papers.
-   [fastai](https://github.com/fastai/fastai) -- Deep learning library
    with CV focus.
    
## Datasets & Benchmarks 

1. [ImageNet](http://www.image-net.org/) — Large-scale image classification dataset.  
2. [COCO](https://cocodataset.org/) — Common Objects in Context for detection, segmentation, captions.  
3. [Open Images Dataset](https://storage.googleapis.com/openimages/web/index.html) — 9M images with object labels and boxes.  
4. [Pascal VOC](http://host.robots.ox.ac.uk/pascal/VOC/) — Classic detection/segmentation benchmark.  
5. [Cityscapes](https://www.cityscapes-dataset.com/) — Urban scene understanding dataset.  
6. [KITTI Vision Benchmark](http://www.cvlibs.net/datasets/kitti/) — Autonomous driving benchmarks.  
7. [Mapillary Vistas](https://www.mapillary.com/dataset/vistas) — Street-level semantic segmentation.  
8. [Waymo Open Dataset](https://waymo.com/open/) — Perception dataset for autonomous driving.  
9. [BDD100K](https://bdd-data.berkeley.edu/) — 100K driving video dataset.  
10. [ApolloScape](http://apolloscape.auto/) — Large-scale autonomous driving dataset.  
11. [nuScenes](https://www.nuscenes.org/) — Autonomous driving multimodal dataset.  
12. [Argoverse](https://www.argoverse.org/) — Self-driving perception and forecasting.  
13. [MOTChallenge](https://motchallenge.net/) — Multi-object tracking benchmark.  
14. [DAVIS](https://davischallenge.org/) — Video object segmentation benchmark.  
15. [YouTube-VOS](https://youtube-vos.org/) — Large-scale video object segmentation dataset.  
16. [Kinetics](https://deepmind.com/research/open-source/kinetics) — Action recognition dataset.  
17. [Something-Something V2](https://developer.qualcomm.com/software/ai-datasets/something-something) — Fine-grained action dataset.  
18. [ActivityNet](http://activity-net.org/) — Large-scale video benchmark.  
19. [AVA](https://research.google.com/ava/) — Atomic visual actions dataset.  
20. [Charades](http://allenai.org/plato/charades/) — Indoor activity dataset.  
21. [MPII Human Pose](http://human-pose.mpi-inf.mpg.de/) — 2D human pose dataset.  
22. [COCO Keypoints](https://cocodataset.org/#keypoints-2020) — Human keypoint dataset.  
23. [Human3.6M](http://vision.imar.ro/human3.6m/) — 3D human poses dataset.  
24. [3DPW](https://virtualhumans.mpi-inf.mpg.de/3DPW/) — 3D poses in the wild.  
25. [Panoptic Studio](http://domedb.perception.cs.cmu.edu/) — Multi-view human dataset.  
26. [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) — Large-scale celebrity face dataset.  
27. [FFHQ](https://github.com/NVlabs/ffhq-dataset) — Flickr-Faces HQ dataset.  
28. [LFW (Labeled Faces in the Wild)](http://vis-www.cs.umass.edu/lfw/) — Face verification dataset.  
29. [MegaFace](http://megaface.cs.washington.edu/) — Large-scale face recognition benchmark.  
30. [VGGFace2](http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/) — Large-scale face dataset.  
31. [MS-Celeb-1M](https://www.microsoft.com/en-us/research/project/ms-celeb-1m-challenge-recognizing-one-million-celebrities-in-the-real-world/) — Celebrity recognition.  
32. [ADE20K](https://groups.csail.mit.edu/vision/datasets/ADE20K/) — Scene parsing dataset.  
33. [SUN Database](https://vision.princeton.edu/projects/2010/SUN/) — Scene recognition dataset.  
34. [Places365](http://places2.csail.mit.edu/) — Scene recognition dataset.  
35. [MIT Indoor Scenes](http://web.mit.edu/torralba/www/indoor.html) — Indoor scene dataset.  
36. [PASCAL Context](http://host.robots.ox.ac.uk/pascal/VOC/voc2010/#devkit) — Scene parsing benchmark.  
37. [DeepFashion](http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html) — Large-scale clothing dataset.  
38. [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) — Simple clothing dataset.  
39. [Stanford Cars](http://ai.stanford.edu/~jkrause/cars/car_dataset.html) — Fine-grained car classification.  
40. [CUB-200-2011 Birds](http://www.vision.caltech.edu/visipedia/CUB-200.html) — Fine-grained bird dataset.  

------------------------------------------------------------------------

## Industry & Labs

-   [OpenAI](https://openai.com/research) -- Multimodal AI research.
-   [DeepMind](https://deepmind.com/research) -- Vision and ML
    breakthroughs.
-   [Meta AI](https://ai.facebook.com/research) -- Computer vision
    research.
 
## Research Labs & Conferences 

1. [CVPR](https://cvpr.thecvf.com/) — IEEE Conference on Computer Vision and Pattern Recognition.  
2. [ICCV](https://iccv.thecvf.com/) — International Conference on Computer Vision.  
3. [ECCV](https://eccv.ecva.net/) — European Conference on Computer Vision.  
4. [NeurIPS](https://nips.cc/) — Neural Information Processing Systems.  
5. [ICLR](https://iclr.cc/) — International Conference on Learning Representations.  
6. [AAAI](https://aaai.org/) — AAAI Conference on Artificial Intelligence.  
7. [IJCAI](https://ijcai.org/) — International Joint Conference on AI.  
8. [BMVC](https://bmvc2024.org/) — British Machine Vision Conference.  
9. [ACCV](https://accv2024.org/) — Asian Conference on Computer Vision.  
10. [WACV](https://wacv2025.thecvf.com/) — Winter Conference on Applications of CV.  
11. [Dagstuhl Seminars on CV](https://www.dagstuhl.de/en/seminars/) — Research workshops.  
12. [Stanford Vision Lab](http://vision.stanford.edu/) — Foundational CV research.  
13. [Berkeley AI Research (BAIR)](https://bair.berkeley.edu/) — Top vision and AI group.  
14. [MIT CSAIL Vision](https://www.csail.mit.edu/research/computer-vision) — Cutting-edge research.  
15. [CMU Perceptual Computing Lab](http://perception.cs.cmu.edu/) — Pioneers of OpenPose.  
16. [Oxford VGG (Visual Geometry Group)](https://www.robots.ox.ac.uk/~vgg/) — Famous for ImageNet & deep nets.  
17. [ETH Zurich CVG](https://vision.ee.ethz.ch/en/) — CV & robotics.  
18. [EPFL CVLab](https://www.epfl.ch/labs/cvlab/) — Swiss CV research lab.  
19. [MPI for Intelligent Systems](https://is.mpg.de/) — Max Planck Institute vision projects.  
20. [University of Toronto Machine Learning Group](https://www.cs.toronto.edu/ml/) — Geoffrey Hinton’s group.  
21. [NYU Center for Data Science](https://cds.nyu.edu/) — Yann LeCun’s lab.  
22. [DeepMind](https://deepmind.com/research) — Pioneering vision & AI.  
23. [Google Research Vision](https://research.google/teams/brain/vision/) — Google AI vision team.  
24. [Meta AI (FAIR)](https://ai.meta.com/research/) — Research in CV & generative models.  
25. [Microsoft Research AI](https://www.microsoft.com/en-us/research/lab/microsoft-research-ai/) — Computer vision research.  
26. [Amazon Science](https://www.amazon.science/) — CV for retail, robotics, AWS.  
27. [NVIDIA Research](https://research.nvidia.com/) — CV, graphics, generative AI.  
28. [Adobe Research](https://research.adobe.com/) — Image/video editing vision research.  
29. [Intel Labs](https://www.intel.com/content/www/us/en/research/overview.html) — Vision hardware/software research.  
30. [Toyota Research Institute](https://www.tri.global/research) — CV for robotics and driving.  
31. [OpenAI](https://openai.com/research) — Multimodal AI research.  
32. [Huawei Noah’s Ark Lab](https://www.noahlab.com.hk/) — Large-scale AI/CV research.  
33. [Tencent AI Lab](https://ai.tencent.com/ailab/en/index) — Research in CV & ML.  
34. [Baidu Research](https://research.baidu.com/) — CV and multimodal AI projects.  
35. [SenseTime Research](https://www.sensetime.com/en/research) — Applied computer vision.  
36. [Megvii (Face++)](https://en.megvii.com/research) — Face recognition & vision.  
37. [OpenMMLab](https://openmmlab.com/) — Open-source CV research ecosystem.  
38. [Robotics Institute at CMU](https://www.ri.cmu.edu/) — CV for robotics and autonomy.  
39. [ICRA](https://www.ieee-ras.org/conferences-workshops/fully-sponsored/icra) — Robotics + CV applications.  
40. [IROS](https://iros2025.org/) — Robotics & vision applications conference.  

## Industry Tools & Frameworks 

1. [OpenCV](https://github.com/opencv/opencv) — The most widely used computer vision library.  
2. [scikit-image](https://scikit-image.org/) — Image processing in Python.  
3. [SimpleCV](https://github.com/sightmachine/SimpleCV) — Framework for building CV apps.  
4. [Kornia](https://github.com/kornia/kornia) — Differentiable CV library for PyTorch.  
5. [PIL / Pillow](https://python-pillow.org/) — Python Imaging Library fork.  
6. [torchvision](https://pytorch.org/vision/stable/index.html) — Datasets, models, and transforms for PyTorch.  
7. [TensorFlow Hub](https://www.tensorflow.org/hub) — Pre-trained vision models.  
8. [Timm (PyTorch Image Models)](https://github.com/huggingface/pytorch-image-models) — Huge collection of pretrained models.  
9. [Albumentations](https://github.com/albumentations-team/albumentations) — Fast image augmentation library.  
10. [AugLy](https://github.com/facebookresearch/AugLy) — Data augmentations for images, audio, and video.  
11. [imgaug](https://github.com/aleju/imgaug) — Image augmentation library.  
12. [MMCV](https://github.com/open-mmlab/mmcv) — OpenMMLab’s core vision library.  
13. [MMDetection](https://github.com/open-mmlab/mmdetection) — Detection toolbox.  
14. [MMSegmentation](https://github.com/open-mmlab/mmsegmentation) — Segmentation toolbox.  
15. [MMTracking](https://github.com/open-mmlab/mmtracking) — Multi-object tracking.  
16. [MMAction2](https://github.com/open-mmlab/mmaction2) — Video understanding.  
17. [OpenMMLab](https://openmmlab.com/) — Complete CV ecosystem.  
18. [NVIDIA DALI](https://github.com/NVIDIA/DALI) — Data loading and augmentation.  
19. [NVIDIA TAO Toolkit](https://developer.nvidia.com/tao-toolkit) — Training vision models.  
20. [OpenVINO](https://github.com/openvinotoolkit/openvino) — Inference engine for edge and cloud.  
21. [ONNX Runtime](https://onnxruntime.ai/) — Deploy ML/CV models across frameworks.  
22. [TensorRT](https://developer.nvidia.com/tensorrt) — High-performance inference library.  
23. [DeepStream SDK](https://developer.nvidia.com/deepstream-sdk) — Video analytics at scale.  
24. [PyTorch Lightning](https://www.pytorchlightning.ai/) — Training framework with CV integrations.  
25. [fastai](https://github.com/fastai/fastai) — Easy-to-use DL for vision.  
26. [Detectron2](https://github.com/facebookresearch/detectron2) — Modular detection framework.  
27. [Segment Anything](https://github.com/facebookresearch/segment-anything) — Foundation segmentation model.  
28. [TorchGeo](https://github.com/microsoft/torchgeo) — Geospatial CV library.  
29. [SuperGradients](https://github.com/Deci-AI/super-gradients) — Training library for CV models.  
30. [IceVision](https://github.com/airctic/icevision) — Unified CV framework.  
31. [FiftyOne](https://github.com/voxel51/fiftyone) — Dataset visualization and management.  
32. [ClearML](https://github.com/allegroai/clearml) — Experiment and dataset management.  
33. [Weights & Biases](https://wandb.ai/) — Experiment tracking for CV projects.  
34. [LabelImg](https://github.com/heartexlabs/labelImg) — Image labeling tool.  
35. [CVAT](https://github.com/opencv/cvat) — Computer vision annotation tool.  
36. [Supervisely](https://supervise.ly/) — CV dataset management and labeling.  
37. [Roboflow](https://roboflow.com/) — Dataset prep and deployment platform.  
38. [VOTT (Visual Object Tagging Tool)](https://github.com/microsoft/VoTT) — Microsoft annotation tool.  
39. [Label Studio](https://github.com/heartexlabs/label-studio) — General-purpose labeling platform.  
40. [Lightly](https://github.com/lightly-ai/lightly) — Self-supervised learning for dataset curation.  

------------------------------------------------------------------------
   
## Books & Learning Resources 

1. *Computer Vision: Algorithms and Applications* by Richard Szeliski — [Book PDF](http://szeliski.org/Book/)  
2. *Deep Learning for Vision Systems* by Mohamed Elgendy — Practical DL applications in vision.  
3. *Programming Computer Vision with Python* by Jan Erik Solem — Hands-on CV with Python.  
4. *Learning OpenCV 4* by Adrian Kaehler & Gary Bradski — The OpenCV classic.  
5. *Multiple View Geometry in Computer Vision* by Richard Hartley & Andrew Zisserman — Geometry foundations.  
6. *Robotics, Vision and Control* by Peter Corke — Vision for robotics.  
7. *Pattern Recognition and Machine Learning* by Christopher Bishop — Theoretical foundations.  
8. *Deep Learning* by Ian Goodfellow, Yoshua Bengio, Aaron Courville — Core DL book.  
9. *Probabilistic Graphical Models* by Daphne Koller — For structured vision models.  
10. *Digital Image Processing* by Gonzalez & Woods — Intro to image processing.  
11. *Modern Computer Vision with PyTorch* by V. Venkatesh — Practical PyTorch-based CV.  
12. *Practical Deep Learning for Cloud, Mobile & Edge* by Anirudh Koul — Real-world projects.  
13. *Computer Vision: A Modern Approach* by Forsyth & Ponce — Classic vision text.  
14. *Bayesian Reasoning and Machine Learning* by David Barber — Probabilistic ML.  
15. *AI for Computer Vision* (Packt Publishing) — Practical implementations.  
16. [Stanford CS231n](http://cs231n.stanford.edu/) — CNNs for visual recognition.  
17. [MIT 6.819/6.869](http://6.869.csail.mit.edu/fa19/) — Advances in computer vision.  
18. [CMU 16-720](http://www.cs.cmu.edu/~16385/) — Intro to CV.  
19. [Berkeley CS280](https://people.eecs.berkeley.edu/~trevor/CS280.html) — CV graduate course.  
20. [Oxford VGG Course](http://www.robots.ox.ac.uk/~vgg/practicals/) — Vision course practicals.  
21. [Coursera — Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning) — Andrew Ng’s DL series.  
22. [fast.ai Practical Deep Learning](https://course.fast.ai/) — Hands-on DL.  
23. [Udacity CV Nanodegree](https://www.udacity.com/course/computer-vision-nanodegree--nd891) — CV specialization.  
24. [OpenCV Course](https://opencv.org/courses/) — From OpenCV team.  
25. [PyImageSearch Blog](https://pyimagesearch.com/) — Popular CV tutorials.  
26. [LearnOpenCV](https://learnopencv.com/) — Blog on OpenCV & DL projects.  
27. [DeepLearning.AI Generative AI](https://www.deeplearning.ai/courses/) — Courses on diffusion, transformers.  
28. [MIT OpenCourseWare CV](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-819-advances-in-computer-vision-fall-2018/) — Free course.  
29. [YouTube: Two Minute Papers](https://www.youtube.com/user/keeroyz) — Digestible research.  
30. [YouTube: Yannic Kilcher](https://www.youtube.com/c/YannicKilcher) — Paper explanations.  
31. [YouTube: Henry AI Labs](https://www.youtube.com/c/HenryAILabs) — Vision + AI tutorials.  
32. [YouTube: Sentdex](https://www.youtube.com/user/sentdex) — Python + CV tutorials.  
33. [YouTube: DeepLearningAI](https://www.youtube.com/c/Deeplearningai) — AI lectures.  
34. [Awesome Computer Vision Papers](https://github.com/jbhuang0604/awesome-computer-vision-papers) — Curated paper list.  
35. [CVPR Tutorials](https://cvpr.thecvf.com/) — Leading conference tutorials.  
36. [ECCV Tutorials](https://eccv2024.ecva.net/) — European CV tutorials.  
37. [ICCV Tutorials](https://iccv2023.thecvf.com/) — ICCV tutorials.  
38. [DeepVision](https://deepvision.io/) — Online CV resources.  
39. [CVonline: Vision Resources](http://homepages.inf.ed.ac.uk/rbf/CVonline/) — Huge online directory.  
40. [Awesome Deep Vision](https://github.com/kjw0612/awesome-deep-vision) — Early curated list.  

## Contributing

Pull requests are welcome! Please follow me for more. 